delegation : 
Ce code a pour but de localiser gÃ©ographiquement des donnÃ©es issues dâ€™un fichier CSV, en associant chaque point (dÃ©fini par sa longitude et sa latitude) Ã  une dÃ©lÃ©gation administrative
prÃ©sente dans un fichier shapefile (fichier cartographique vectoriel). Il nettoie dâ€™abord les coordonnÃ©es GPS, crÃ©e une reprÃ©sentation gÃ©ographique des points Ã  lâ€™aide de GeoPandas, puis
effectue une jointure spatiale avec une carte des dÃ©lÃ©gations afin dâ€™identifier Ã  quelle zone administrative chaque point appartient. Enfin, il permet de sauvegarder ces informations enrichies 
et de visualiser les rÃ©sultats sur une carte pour des analyses spatiales.
extract_technology : 
Ce code a pour objectif de traiter des colonnes contenant du texte au format JSON dans un fichier CSV, afin dâ€™en extraire automatiquement les noms de technologies et
les offres associÃ©es, puis de les stocker dans de nouvelles colonnes plus facilement exploitables.

Voici ce que fait chaque Ã©tape :

    Lecture du fichier CSV : le fichier source (data_fixed.csv) est chargÃ© avec le bon sÃ©parateur (|).

    Traitement du JSON : une fonction corrige les chaÃ®nes de caractÃ¨res JSON mal formatÃ©es (apostrophes, boolÃ©ens) et extrait :

        les noms des technologies (technology_name)

        les noms des offres (offer_name) contenues dans chaque technologie

    Application de la fonction :

        Dâ€™abord sur la colonne response_body (rÃ©ponse reÃ§ue)

        Puis sur request_body (requÃªte envoyÃ©e)
        Les rÃ©sultats sont stockÃ©s dans des colonnes comme response_extracted_technologies, response_offers, etc.

    Export final : les nouvelles donnÃ©es enrichies sont sauvegardÃ©es dans un fichier CSV (data_extracted.csv).

ğŸ‘‰ Ce traitement permet de structurer des informations complexes imbriquÃ©es dans des champs JSON pour faciliter les analyses futures (comptage, filtrage, etc.).
group_donnees : 
Ce script a pour objectif de prÃ©parer des donnÃ©es de couverture technologique par date et localisation, en nettoyant et en structurant les informations extraites prÃ©cÃ©demment. Voici une explication dÃ©taillÃ©e de chaque Ã©tape :
ğŸ”¹ 1. Chargement des donnÃ©es

Le fichier CSV contenant les donnÃ©es enrichies (df_with_delegations.csv) est chargÃ©.
ğŸ”¹ 2. Nettoyage du texte

La colonne response_extracted_technologies est convertie en minuscules pour faciliter la recherche de mots-clÃ©s (comme "4g", "fibre", etc.).
ğŸ”¹ 3. Transformation temporelle

La colonne requested_at est convertie en format datetime. Une nouvelle colonne jour est ensuite crÃ©Ã©e pour ne conserver que la date (sans l'heure).
ğŸ”¹ 4. Comptage des technologies


Chaque dÃ©tection est convertie en 1 (prÃ©sente) ou 0 (absente) via une regex, ce qui permet un comptage binaire. Les valeurs sont ensuite converties en entiers.
ğŸ”¹ 5. AgrÃ©gation par jour et localisation

Les donnÃ©es sont groupÃ©es par jour, ip_address, longitude, latitude, puis on somme les valeurs binaires des technologies pour obtenir un nombre dâ€™occurrences par site et par jour.
ğŸ”¹ 6. Sortie

Le DataFrame df_counts contient dÃ©sormais les comptages journaliers de chaque technologie par position gÃ©ographique.

ğŸ’¡ UtilitÃ© : Cette prÃ©paration est idÃ©ale pour des analyses temporelles ou spatiales des technologies prÃ©sentes (ex. : carte de chaleur, sÃ©ries temporelles, prÃ©visions).
